{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"LoadingAndTestingTrainedModel.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K2s1A9eLRPEj"},"source":["##### Copyright 2018 The TensorFlow Authors.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U8l4RJ0XRPEm","colab":{},"executionInfo":{"status":"ok","timestamp":1594724443387,"user_tz":-300,"elapsed":8266,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["import tensorflow as tf\n","from nltk.translate.bleu_score import corpus_bleu\n","\n","# You'll generate plots of attention in order to see which parts of an image\n","# our model focuses on during captioning\n","import matplotlib.pyplot as plt\n","\n","# Scikit-learn includes many helpful utilities\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","import re\n","import numpy as np\n","import os\n","import time\n","import json\n","from glob import glob\n","from PIL import Image\n","import pickle"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zXR0217aRPFR","colab":{},"executionInfo":{"status":"ok","timestamp":1594724486558,"user_tz":-300,"elapsed":18180,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["def load_image(image_path):\n","    img = tf.io.read_file(image_path)\n","    img = tf.image.decode_jpeg(img, channels=3)\n","    img = tf.image.resize(img, (299, 299))\n","    img = tf.keras.applications.inception_v3.preprocess_input(img)\n","    return img, image_path"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"rEkbxsqyxPb7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594724486561,"user_tz":-300,"elapsed":18168,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":[""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RD3vW4SsRPFW","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594724507353,"user_tz":-300,"elapsed":38952,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}},"outputId":"81db9abf-b3b9-443a-f0e9-1d9da9a317e7"},"source":["image_model = tf.keras.applications.InceptionV3(include_top=False,\n","                                                weights='imagenet')\n","new_input = image_model.input\n","hidden_layer = image_model.layers[-1].output\n","\n","image_features_extract_model = tf.keras.Model(new_input, hidden_layer)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Q3TnZ1ToRPGV","colab":{},"executionInfo":{"status":"ok","timestamp":1594724792413,"user_tz":-300,"elapsed":2224,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["# Feel free to change these parameters according to your system's configuration\n","\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 1000\n","embedding_dim = 256\n","img_name_train = []\n","top_k = 5000\n","units = 512\n","vocab_size = top_k + 1\n","num_steps = len(img_name_train) // BATCH_SIZE\n","# Shape of the vector extracted from InceptionV3 is (64, 2048)\n","# These two variables represent that vector shape\n","features_shape = 2048\n","attention_features_shape = 64\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SmZS2N0bXG3T","colab":{},"executionInfo":{"status":"ok","timestamp":1594724792415,"user_tz":-300,"elapsed":1440,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["# Load the numpy files\n","def map_func(img_name, cap):\n","  img_tensor = np.load(img_name.decode('utf-8')+'.npy')\n","  return img_tensor, cap"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FDF_Nm3tRPGZ","colab":{},"executionInfo":{"status":"ok","timestamp":1594724793451,"user_tz":-300,"elapsed":1996,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["cap_train =[]\n","dataset = tf.data.Dataset.from_tensor_slices((img_name_train, cap_train))\n","\n","# Use map to load the numpy files in parallel\n","dataset = dataset.map(lambda item1, item2: tf.numpy_function(\n","          map_func, [item1, item2], [tf.float32, tf.int32]),\n","          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","\n","# Shuffle and batch\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n","dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ja2LFTMSdeV3","colab":{},"executionInfo":{"status":"ok","timestamp":1594724793454,"user_tz":-300,"elapsed":1683,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["class BahdanauAttention(tf.keras.Model):\n","  def __init__(self, units):\n","    super(BahdanauAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, features, hidden):\n","    # features(CNN_encoder output) shape == (batch_size, 64, embedding_dim)\n","\n","    # hidden shape == (batch_size, hidden_size)\n","    # hidden_with_time_axis shape == (batch_size, 1, hidden_size)\n","    hidden_with_time_axis = tf.expand_dims(hidden, 1)\n","\n","    # score shape == (batch_size, 64, hidden_size)\n","    score = tf.nn.tanh(self.W1(features) + self.W2(hidden_with_time_axis))\n","\n","    # attention_weights shape == (batch_size, 64, 1)\n","    # you get 1 at the last axis because you are applying score to self.V\n","    attention_weights = tf.nn.softmax(self.V(score), axis=1)\n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * features\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    return context_vector, attention_weights"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AZ7R1RxHRPGf","colab":{},"executionInfo":{"status":"ok","timestamp":1594724795377,"user_tz":-300,"elapsed":3253,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["class CNN_Encoder(tf.keras.Model):\n","    # Since you have already extracted the features and dumped it using pickle\n","    # This encoder passes those features through a Fully connected layer\n","    def __init__(self, embedding_dim):\n","        super(CNN_Encoder, self).__init__()\n","        # shape after fc == (batch_size, 64, embedding_dim)\n","        self.fc = tf.keras.layers.Dense(embedding_dim)\n","\n","    def call(self, x):\n","        x = self.fc(x)\n","        x = tf.nn.relu(x)\n","        return x"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"V9UbGQmERPGi","colab":{},"executionInfo":{"status":"ok","timestamp":1594724795381,"user_tz":-300,"elapsed":3012,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["class RNN_Decoder(tf.keras.Model):\n","  def __init__(self, embedding_dim, units, vocab_size):\n","    super(RNN_Decoder, self).__init__()\n","    self.units = units\n","\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc1 = tf.keras.layers.Dense(self.units)\n","    self.fc2 = tf.keras.layers.Dense(vocab_size)\n","\n","    self.attention = BahdanauAttention(self.units)\n","\n","  def call(self, x, features, hidden):\n","    # defining attention as a separate model\n","    context_vector, attention_weights = self.attention(features, hidden)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state = self.gru(x)\n","\n","    # shape == (batch_size, max_length, hidden_size)\n","    x = self.fc1(output)\n","\n","    # x shape == (batch_size * max_length, hidden_size)\n","    x = tf.reshape(x, (-1, x.shape[2]))\n","\n","    # output shape == (batch_size * max_length, vocab)\n","    x = self.fc2(x)\n","\n","    return x, state, attention_weights\n","\n","  def reset_state(self, batch_size):\n","    return tf.zeros((batch_size, self.units))"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qs_Sr03wRPGk","colab":{},"executionInfo":{"status":"ok","timestamp":1594724795388,"user_tz":-300,"elapsed":2810,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["encoder = CNN_Encoder(embedding_dim)\n","decoder = RNN_Decoder(embedding_dim, units, vocab_size)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-bYN7xA0RPGl","colab":{},"executionInfo":{"status":"ok","timestamp":1594724795391,"user_tz":-300,"elapsed":2490,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["optimizer = tf.keras.optimizers.Adam()\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"VaiUKBqB_cD2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594724795394,"user_tz":-300,"elapsed":2307,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}},"outputId":"57fd742c-1fcd-4829-f1f5-b69841b5981a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rou_kfQN7Y4B","colab_type":"text"},"source":["#Loading weights and data"]},{"cell_type":"code","metadata":{"id":"SW9FDmY77eEH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594724795396,"user_tz":-300,"elapsed":1495,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}},"outputId":"2809e62b-769e-4fa6-c7c3-62b710975f0d"},"source":["# Load the state of the old model\n","path = \"/content/drive/My Drive/CaptioningModel/decoder\"\n","decoder.load_weights(path)\n","\n","path = \"/content/drive/My Drive/CaptioningModel/encoder\"\n","encoder.load_weights(path)"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb46f52eeb8>"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"qHhAqFF072Bw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594724796117,"user_tz":-300,"elapsed":1390,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["#run this cell\n","#loading vocabulary\n","\n","with open('/content/drive/My Drive/CaptioningModel/word_index.json', 'r') as fp:\n","    word_index = json.load(fp)\n","\n","with open('/content/drive/My Drive/CaptioningModel/index_word.json', 'r') as fp:\n","    index_word = json.load(fp)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"zpxujPZ17ehz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594724797143,"user_tz":-300,"elapsed":1445,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["max_length=49\n","attention_features_shape=64"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"vysxgZNk7eaV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594724797898,"user_tz":-300,"elapsed":1542,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":[""],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RCWpDtyNRPGs","colab":{},"executionInfo":{"status":"ok","timestamp":1594724798712,"user_tz":-300,"elapsed":1807,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["def evaluate(image):\n","    attention_plot = np.zeros((max_length, attention_features_shape))\n","\n","    hidden = decoder.reset_state(batch_size=1)\n","\n","    temp_input = tf.expand_dims(load_image(image)[0], 0)\n","    img_tensor_val = image_features_extract_model(temp_input)\n","    img_tensor_val = tf.reshape(img_tensor_val, (img_tensor_val.shape[0], -1, img_tensor_val.shape[3]))\n","\n","    features = encoder(img_tensor_val)\n","\n","    dec_input = tf.expand_dims([word_index['<start>']], 0)\n","    result = []\n","\n","    for i in range(max_length):\n","        predictions, hidden, attention_weights = decoder(dec_input, features, hidden)\n","\n","        attention_plot[i] = tf.reshape(attention_weights, (-1, )).numpy()\n","\n","        predicted_id = tf.random.categorical(predictions, 1)[0][0].numpy()\n","        result.append(index_word[str(predicted_id)])\n","\n","        if index_word[str(predicted_id)] == '<end>':\n","            return result, attention_plot\n","\n","        dec_input = tf.expand_dims([predicted_id], 0)\n","\n","    attention_plot = attention_plot[:len(result), :]\n","    return result, attention_plot"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fD_y7PD6RPGt","colab":{},"executionInfo":{"status":"ok","timestamp":1594724799561,"user_tz":-300,"elapsed":1937,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["def plot_attention(image, result, attention_plot):\n","    temp_image = np.array(Image.open(image))\n","\n","    fig = plt.figure(figsize=(10, 10))\n","\n","    len_result = len(result)\n","    for l in range(len_result):\n","        temp_att = np.resize(attention_plot[l], (8, 8))\n","        ax = fig.add_subplot(len_result//2, len_result//2, l+1)\n","        ax.set_title(result[l])\n","        img = ax.imshow(temp_image)\n","        ax.imshow(temp_att, cmap='gray', alpha=0.6, extent=img.get_extent())\n","\n","    plt.tight_layout()\n","    plt.show()"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7x8RiPHe_4qI","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1594725611679,"user_tz":-300,"elapsed":1748,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}},"outputId":"0396b3f9-532d-4f7e-8647-04fff173f28e"},"source":["# captions on the validation set\n","img_name_val = [1000]\n","cap_val = []\n","rid = np.random.randint(0, len(img_name_val))\n","image = img_name_val[rid]\n","real_caption = ' '.join([tokenizer.index_word[i] for i in cap_val[rid] if i not in [0]])\n","result, attention_plot = evaluate(image)\n","\n","print ('Real Caption:', real_caption)\n","print ('Prediction Caption:', ' '.join(result))\n","plot_attention(image, result, attention_plot)\n","Image.open(image)\n"],"execution_count":54,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-34da72024e5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_name_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mreal_caption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcap_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","metadata":{"id":"z3grW-ukEwAw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594725963869,"user_tz":-300,"elapsed":1276,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}}},"source":["def realCaption(path):\n","  with open(\"/content/datasetV2/annotations.json\", 'r') as jsonfile:\n","    file= json.load(jsonfile)\n","\n","  for dic in file:\n","    if(dic['name']==path[16:44]):\n","      return dic['caption']"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9Psd1quzaAWg","colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"status":"error","timestamp":1594725999871,"user_tz":-300,"elapsed":1672,"user":{"displayName":"Laeeq Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzZoaXU9xBmFNXXDOELEDhKEFtaSh8xSjOuNqS=s64","userId":"13731562276918248683"}},"outputId":"746588cc-7bdc-45b7-db83-f18e703f402c"},"source":["image_url = 'https://homepages.cae.wisc.edu/~ece533/images/cat.png'\n","#https://homepages.cae.wisc.edu/~ece533/images/  Website contain online images\n","image_extension = image_url[-4:]\n","image_path = tf.keras.utils.get_file('image'+image_extension,\n","                                     origin=image_url)\n","score= realCaption(image_path)\n","result, attention_plot = evaluate(image_path)\n","print ('Prediction Caption:', ' '.join(result))\n","plot_attention(image_path, result, attention_plot)\n","# opening the image\n","Image.open(image_path)"],"execution_count":56,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-05e75acf4d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m image_path = tf.keras.utils.get_file('image'+image_extension,\n\u001b[1;32m      5\u001b[0m                                      origin=image_url)\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrealCaption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction Caption:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-55-4bfe3dff836f>\u001b[0m in \u001b[0;36mrealCaption\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrealCaption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/datasetV2/annotations.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjsonfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/datasetV2/annotations.json'"]}]},{"cell_type":"code","metadata":{"id":"f59xVSZ2_Pd3","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}